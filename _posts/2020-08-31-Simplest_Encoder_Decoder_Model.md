---
layout: post
title: Simplest Encoder Decoder Model
published: true
---

This post is going to present the simplest Encoder-Decoder model which reproduces a set of strings. Additionally, this post will also present the purpose of each layer used in Encoder and Decoder.
<p align="center">
<img src="/assets/2020-08-31-simple_encoder_decoder/seq2seq_model.png" alt="Simplest encoder-decoder architecture." width="800" >
</p>


Keywords:

1. Deep Learning
2. Encoder/Decoder
3. Embedding Layer
4. NLP

<!--more-->


---

## 1. Sequence-to-Sequence model

Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button for formatting help.

---

## 2. Encoder

Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button for formatting help.

---

## 3. Decoder

Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button for formatting help.

---

## 4. Layer Purpose Explanation

Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button for formatting help.

---

## Further Learning

---

## References

1. [Deploying a seq2seq model with torchscript](https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html)


